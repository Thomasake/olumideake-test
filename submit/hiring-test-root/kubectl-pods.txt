Name:                 local-path-provisioner-84db5d44d9-pkp5r
Namespace:            kube-system
Priority:             2000001000
Priority Class Name:  system-node-critical
Service Account:      local-path-provisioner-service-account
Node:                 mtl-w-4brym13/172.26.138.62
Start Time:           Tue, 27 Feb 2024 11:14:07 -0700
Labels:               app=local-path-provisioner
                      pod-template-hash=84db5d44d9
Annotations:          <none>
Status:               Running
IP:                   10.42.0.3
IPs:
  IP:           10.42.0.3
Controlled By:  ReplicaSet/local-path-provisioner-84db5d44d9
Containers:
  local-path-provisioner:
    Container ID:  containerd://4039027c0401fddd6082135e023df2181eb81e4650d4caecc34052601448e66a
    Image:         rancher/local-path-provisioner:v0.0.24
    Image ID:      docker.io/rancher/local-path-provisioner@sha256:5bb33992a4ec3034c28b5e0b3c4c2ac35d3613b25b79455eb4b1a95adc82cdc0
    Port:          <none>
    Host Port:     <none>
    Command:
      local-path-provisioner
      start
      --config
      /etc/config/config.json
    State:          Running
      Started:      Tue, 27 Feb 2024 11:14:16 -0700
    Ready:          True
    Restart Count:  0
    Environment:
      POD_NAMESPACE:  kube-system (v1:metadata.namespace)
    Mounts:
      /etc/config/ from config-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-ntxrz (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      local-path-config
    Optional:  false
  kube-api-access-ntxrz:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 CriticalAddonsOnly op=Exists
                             node-role.kubernetes.io/control-plane:NoSchedule op=Exists
                             node-role.kubernetes.io/master:NoSchedule op=Exists
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  9m12s  default-scheduler  Successfully assigned kube-system/local-path-provisioner-84db5d44d9-pkp5r to mtl-w-4brym13
  Normal  Pulling    9m10s  kubelet            Pulling image "rancher/local-path-provisioner:v0.0.24"
  Normal  Pulled     9m4s   kubelet            Successfully pulled image "rancher/local-path-provisioner:v0.0.24" in 5.832s (5.832s including waiting)
  Normal  Created    9m4s   kubelet            Created container local-path-provisioner
  Normal  Started    9m4s   kubelet            Started container local-path-provisioner


Name:                 coredns-6799fbcd5-ptsvw
Namespace:            kube-system
Priority:             2000000000
Priority Class Name:  system-cluster-critical
Service Account:      coredns
Node:                 mtl-w-4brym13/172.26.138.62
Start Time:           Tue, 27 Feb 2024 11:14:07 -0700
Labels:               k8s-app=kube-dns
                      pod-template-hash=6799fbcd5
Annotations:          <none>
Status:               Running
IP:                   10.42.0.4
IPs:
  IP:           10.42.0.4
Controlled By:  ReplicaSet/coredns-6799fbcd5
Containers:
  coredns:
    Container ID:  containerd://3eb4ed3e3e9513409cfa9699ed46d9ad8476da235062041689b9a9449cf56ca9
    Image:         rancher/mirrored-coredns-coredns:1.10.1
    Image ID:      docker.io/rancher/mirrored-coredns-coredns@sha256:a11fafae1f8037cbbd66c5afa40ba2423936b72b4fd50a7034a7e8b955163594
    Ports:         53/UDP, 53/TCP, 9153/TCP
    Host Ports:    0/UDP, 0/TCP, 0/TCP
    Args:
      -conf
      /etc/coredns/Corefile
    State:          Running
      Started:      Tue, 27 Feb 2024 11:14:18 -0700
    Ready:          True
    Restart Count:  0
    Limits:
      memory:  170Mi
    Requests:
      cpu:        100m
      memory:     70Mi
    Liveness:     http-get http://:8080/health delay=60s timeout=1s period=10s #success=1 #failure=3
    Readiness:    http-get http://:8181/ready delay=0s timeout=1s period=2s #success=1 #failure=3
    Environment:  <none>
    Mounts:
      /etc/coredns from config-volume (ro)
      /etc/coredns/custom from custom-config-volume (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-snh5x (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      coredns
    Optional:  false
  custom-config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      coredns-custom
    Optional:  true
  kube-api-access-snh5x:
    Type:                     Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:   3607
    ConfigMapName:            kube-root-ca.crt
    ConfigMapOptional:        <nil>
    DownwardAPI:              true
QoS Class:                    Burstable
Node-Selectors:               kubernetes.io/os=linux
Tolerations:                  CriticalAddonsOnly op=Exists
                              node-role.kubernetes.io/control-plane:NoSchedule op=Exists
                              node-role.kubernetes.io/master:NoSchedule op=Exists
                              node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                              node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Topology Spread Constraints:  kubernetes.io/hostname:DoNotSchedule when max skew 1 is exceeded for selector k8s-app=kube-dns
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  9m12s  default-scheduler  Successfully assigned kube-system/coredns-6799fbcd5-ptsvw to mtl-w-4brym13
  Normal  Pulling    9m10s  kubelet            Pulling image "rancher/mirrored-coredns-coredns:1.10.1"
  Normal  Pulled     9m3s   kubelet            Successfully pulled image "rancher/mirrored-coredns-coredns:1.10.1" in 7.51s (7.51s including waiting)
  Normal  Created    9m3s   kubelet            Created container coredns
  Normal  Started    9m2s   kubelet            Started container coredns


Name:             helm-install-traefik-crd-bwxnh
Namespace:        kube-system
Priority:         0
Service Account:  helm-traefik-crd
Node:             mtl-w-4brym13/172.26.138.62
Start Time:       Tue, 27 Feb 2024 11:14:07 -0700
Labels:           batch.kubernetes.io/controller-uid=9530b900-e7c7-47b6-ac35-509c0444fa2a
                  batch.kubernetes.io/job-name=helm-install-traefik-crd
                  controller-uid=9530b900-e7c7-47b6-ac35-509c0444fa2a
                  helmcharts.helm.cattle.io/chart=traefik-crd
                  job-name=helm-install-traefik-crd
Annotations:      helmcharts.helm.cattle.io/configHash: SHA256=E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855
Status:           Succeeded
SeccompProfile:   RuntimeDefault
IP:               10.42.0.2
IPs:
  IP:           10.42.0.2
Controlled By:  Job/helm-install-traefik-crd
Containers:
  helm:
    Container ID:  containerd://e087c190264b151c1628dc5db289d9d187ccc4ae94cf042887071efb38813ffc
    Image:         rancher/klipper-helm:v0.8.2-build20230815
    Image ID:      docker.io/rancher/klipper-helm@sha256:b0b0c4f73f2391697edb52adffe4fc490de1c8590606024515bb906b2813554a
    Port:          <none>
    Host Port:     <none>
    Args:
      install
    State:      Terminated
      Reason:   Completed
      Message:  Installing helm_v3 chart

      Exit Code:    0
      Started:      Tue, 27 Feb 2024 11:14:22 -0700
      Finished:     Tue, 27 Feb 2024 11:14:28 -0700
    Ready:          False
    Restart Count:  0
    Environment:
      NAME:                   traefik-crd
      VERSION:                
      REPO:                   
      HELM_DRIVER:            secret
      CHART_NAMESPACE:        kube-system
      CHART:                  https://%{KUBERNETES_API}%/static/charts/traefik-crd-25.0.2+up25.0.0.tgz
      HELM_VERSION:           
      TARGET_NAMESPACE:       kube-system
      AUTH_PASS_CREDENTIALS:  false
      NO_PROXY:               .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
      FAILURE_POLICY:         reinstall
    Mounts:
      /chart from content (rw)
      /config from values (rw)
      /home/klipper-helm/.cache from klipper-cache (rw)
      /home/klipper-helm/.config from klipper-config (rw)
      /home/klipper-helm/.helm from klipper-helm (rw)
      /tmp from tmp (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4bvnm (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  klipper-helm:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  klipper-cache:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  klipper-config:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  tmp:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  values:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  chart-values-traefik-crd
    Optional:    false
  content:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      chart-content-traefik-crd
    Optional:  false
  kube-api-access-4bvnm:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              kubernetes.io/os=linux
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  9m12s  default-scheduler  Successfully assigned kube-system/helm-install-traefik-crd-bwxnh to mtl-w-4brym13
  Normal  Pulling    9m10s  kubelet            Pulling image "rancher/klipper-helm:v0.8.2-build20230815"
  Normal  Pulled     8m59s  kubelet            Successfully pulled image "rancher/klipper-helm:v0.8.2-build20230815" in 11.538s (11.538s including waiting)
  Normal  Created    8m59s  kubelet            Created container helm
  Normal  Started    8m58s  kubelet            Started container helm


Name:                 metrics-server-67c658944b-cwbnw
Namespace:            kube-system
Priority:             2000001000
Priority Class Name:  system-node-critical
Service Account:      metrics-server
Node:                 mtl-w-4brym13/172.26.138.62
Start Time:           Tue, 27 Feb 2024 11:14:07 -0700
Labels:               k8s-app=metrics-server
                      pod-template-hash=67c658944b
Annotations:          <none>
Status:               Running
IP:                   10.42.0.6
IPs:
  IP:           10.42.0.6
Controlled By:  ReplicaSet/metrics-server-67c658944b
Containers:
  metrics-server:
    Container ID:  containerd://f2f008cebaa5f27b569d6581e2e7b0f6dac4560ab92009ea839a7f2307f14f03
    Image:         rancher/mirrored-metrics-server:v0.6.3
    Image ID:      docker.io/rancher/mirrored-metrics-server@sha256:c2dfd72bafd6406ed306d9fbd07f55c496b004293d13d3de88a4567eacc36558
    Port:          10250/TCP
    Host Port:     0/TCP
    Args:
      --cert-dir=/tmp
      --secure-port=10250
      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      --kubelet-use-node-status-port
      --metric-resolution=15s
      --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
    State:          Running
      Started:      Tue, 27 Feb 2024 11:14:19 -0700
    Ready:          True
    Restart Count:  0
    Requests:
      cpu:        100m
      memory:     70Mi
    Liveness:     http-get https://:https/livez delay=60s timeout=1s period=10s #success=1 #failure=3
    Readiness:    http-get https://:https/readyz delay=0s timeout=1s period=2s #success=1 #failure=3
    Environment:  <none>
    Mounts:
      /tmp from tmp-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-m9ljg (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  tmp-dir:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  kube-api-access-m9ljg:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              <none>
Tolerations:                 CriticalAddonsOnly op=Exists
                             node-role.kubernetes.io/control-plane:NoSchedule op=Exists
                             node-role.kubernetes.io/master:NoSchedule op=Exists
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
  Normal   Scheduled  9m12s                  default-scheduler  Successfully assigned kube-system/metrics-server-67c658944b-cwbnw to mtl-w-4brym13
  Normal   Pulling    9m10s                  kubelet            Pulling image "rancher/mirrored-metrics-server:v0.6.3"
  Normal   Pulled     9m1s                   kubelet            Successfully pulled image "rancher/mirrored-metrics-server:v0.6.3" in 8.584s (8.584s including waiting)
  Normal   Created    9m1s                   kubelet            Created container metrics-server
  Normal   Started    9m1s                   kubelet            Started container metrics-server
  Warning  Unhealthy  9m (x3 over 9m1s)      kubelet            Readiness probe failed: Get "https://10.42.0.6:10250/readyz": dial tcp 10.42.0.6:10250: connect: connection refused
  Warning  Unhealthy  8m57s                  kubelet            Readiness probe failed: Get "https://10.42.0.6:10250/readyz": net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)
  Warning  Unhealthy  8m42s (x8 over 8m56s)  kubelet            Readiness probe failed: HTTP probe failed with statuscode: 500


Name:             helm-install-traefik-pbg2d
Namespace:        kube-system
Priority:         0
Service Account:  helm-traefik
Node:             mtl-w-4brym13/172.26.138.62
Start Time:       Tue, 27 Feb 2024 11:14:07 -0700
Labels:           batch.kubernetes.io/controller-uid=7cda5ef1-bf02-4a96-bf62-9d1b3e708d4e
                  batch.kubernetes.io/job-name=helm-install-traefik
                  controller-uid=7cda5ef1-bf02-4a96-bf62-9d1b3e708d4e
                  helmcharts.helm.cattle.io/chart=traefik
                  job-name=helm-install-traefik
Annotations:      helmcharts.helm.cattle.io/configHash: SHA256=2C8876269AFB411F60BCDA289A1957C0126147D80F1B0AC6BD2C43C10FE296E9
Status:           Succeeded
SeccompProfile:   RuntimeDefault
IP:               10.42.0.5
IPs:
  IP:           10.42.0.5
Controlled By:  Job/helm-install-traefik
Containers:
  helm:
    Container ID:  containerd://e032e85c83ee172eb19a78984e5f6e17d98a1b1963442e9b73a2628f36e3c9c9
    Image:         rancher/klipper-helm:v0.8.2-build20230815
    Image ID:      docker.io/rancher/klipper-helm@sha256:b0b0c4f73f2391697edb52adffe4fc490de1c8590606024515bb906b2813554a
    Port:          <none>
    Host Port:     <none>
    Args:
      install
      --set-string
      global.systemDefaultRegistry=
    State:      Terminated
      Reason:   Completed
      Message:  Installing helm_v3 chart

      Exit Code:    0
      Started:      Tue, 27 Feb 2024 11:14:43 -0700
      Finished:     Tue, 27 Feb 2024 11:14:46 -0700
    Ready:          False
    Restart Count:  2
    Environment:
      NAME:                   traefik
      VERSION:                
      REPO:                   
      HELM_DRIVER:            secret
      CHART_NAMESPACE:        kube-system
      CHART:                  https://%{KUBERNETES_API}%/static/charts/traefik-25.0.2+up25.0.0.tgz
      HELM_VERSION:           
      TARGET_NAMESPACE:       kube-system
      AUTH_PASS_CREDENTIALS:  false
      NO_PROXY:               .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
      FAILURE_POLICY:         reinstall
    Mounts:
      /chart from content (rw)
      /config from values (rw)
      /home/klipper-helm/.cache from klipper-cache (rw)
      /home/klipper-helm/.config from klipper-config (rw)
      /home/klipper-helm/.helm from klipper-helm (rw)
      /tmp from tmp (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-7s2wb (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  klipper-helm:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  klipper-cache:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  klipper-config:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  tmp:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  values:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  chart-values-traefik
    Optional:    false
  content:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      chart-content-traefik
    Optional:  false
  kube-api-access-7s2wb:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              kubernetes.io/os=linux
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
  Normal   Scheduled  9m12s                  default-scheduler  Successfully assigned kube-system/helm-install-traefik-pbg2d to mtl-w-4brym13
  Normal   Pulling    9m10s                  kubelet            Pulling image "rancher/klipper-helm:v0.8.2-build20230815"
  Normal   Pulled     8m59s                  kubelet            Successfully pulled image "rancher/klipper-helm:v0.8.2-build20230815" in 11.38s (11.381s including waiting)
  Warning  BackOff    8m52s                  kubelet            Back-off restarting failed container helm in pod helm-install-traefik-pbg2d_kube-system(0580dd46-892e-405e-9641-ad74ece7b981)
  Normal   Pulled     8m37s (x2 over 8m55s)  kubelet            Container image "rancher/klipper-helm:v0.8.2-build20230815" already present on machine
  Normal   Created    8m37s (x3 over 8m59s)  kubelet            Created container helm
  Normal   Started    8m37s (x3 over 8m58s)  kubelet            Started container helm


Name:             svclb-traefik-c42f2c04-chxbj
Namespace:        kube-system
Priority:         0
Service Account:  svclb
Node:             mtl-w-4brym13/172.26.138.62
Start Time:       Tue, 27 Feb 2024 11:14:46 -0700
Labels:           app=svclb-traefik-c42f2c04
                  controller-revision-hash=749c84f7df
                  pod-template-generation=1
                  svccontroller.k3s.cattle.io/svcname=traefik
                  svccontroller.k3s.cattle.io/svcnamespace=kube-system
Annotations:      <none>
Status:           Running
IP:               10.42.0.7
IPs:
  IP:           10.42.0.7
Controlled By:  DaemonSet/svclb-traefik-c42f2c04
Containers:
  lb-tcp-80:
    Container ID:   containerd://245434d48d54bebc7d063944cd789c5eeb1a39bd5c212985a4130509256b1137
    Image:          rancher/klipper-lb:v0.4.5
    Image ID:       docker.io/rancher/klipper-lb@sha256:fa2257de248f46c303d0f39a8ebe8644ba5ac63d332c7d02bf6ee26a981243bc
    Port:           80/TCP
    Host Port:      80/TCP
    State:          Running
      Started:      Tue, 27 Feb 2024 11:14:51 -0700
    Ready:          True
    Restart Count:  0
    Environment:
      SRC_PORT:    80
      SRC_RANGES:  0.0.0.0/0
      DEST_PROTO:  TCP
      DEST_PORT:   80
      DEST_IPS:    10.43.132.65
    Mounts:        <none>
  lb-tcp-443:
    Container ID:   containerd://2ee8184012c3d06c08ff597e7cd26755e9d07fc05b77938dd983993a475dbea2
    Image:          rancher/klipper-lb:v0.4.5
    Image ID:       docker.io/rancher/klipper-lb@sha256:fa2257de248f46c303d0f39a8ebe8644ba5ac63d332c7d02bf6ee26a981243bc
    Port:           443/TCP
    Host Port:      443/TCP
    State:          Running
      Started:      Tue, 27 Feb 2024 11:14:51 -0700
    Ready:          True
    Restart Count:  0
    Environment:
      SRC_PORT:    443
      SRC_RANGES:  0.0.0.0/0
      DEST_PROTO:  TCP
      DEST_PORT:   443
      DEST_IPS:    10.43.132.65
    Mounts:        <none>
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:            <none>
QoS Class:          BestEffort
Node-Selectors:     <none>
Tolerations:        CriticalAddonsOnly op=Exists
                    node-role.kubernetes.io/control-plane:NoSchedule op=Exists
                    node-role.kubernetes.io/master:NoSchedule op=Exists
                    node.kubernetes.io/disk-pressure:NoSchedule op=Exists
                    node.kubernetes.io/memory-pressure:NoSchedule op=Exists
                    node.kubernetes.io/not-ready:NoExecute op=Exists
                    node.kubernetes.io/pid-pressure:NoSchedule op=Exists
                    node.kubernetes.io/unreachable:NoExecute op=Exists
                    node.kubernetes.io/unschedulable:NoSchedule op=Exists
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  8m33s  default-scheduler  Successfully assigned kube-system/svclb-traefik-c42f2c04-chxbj to mtl-w-4brym13
  Normal  Pulling    8m33s  kubelet            Pulling image "rancher/klipper-lb:v0.4.5"
  Normal  Pulled     8m30s  kubelet            Successfully pulled image "rancher/klipper-lb:v0.4.5" in 3.249s (3.249s including waiting)
  Normal  Created    8m30s  kubelet            Created container lb-tcp-80
  Normal  Started    8m29s  kubelet            Started container lb-tcp-80
  Normal  Pulled     8m29s  kubelet            Container image "rancher/klipper-lb:v0.4.5" already present on machine
  Normal  Created    8m29s  kubelet            Created container lb-tcp-443
  Normal  Started    8m29s  kubelet            Started container lb-tcp-443


Name:                 traefik-f4564c4f4-4xlbt
Namespace:            kube-system
Priority:             2000000000
Priority Class Name:  system-cluster-critical
Service Account:      traefik
Node:                 mtl-w-4brym13/172.26.138.62
Start Time:           Tue, 27 Feb 2024 11:14:46 -0700
Labels:               app.kubernetes.io/instance=traefik-kube-system
                      app.kubernetes.io/managed-by=Helm
                      app.kubernetes.io/name=traefik
                      helm.sh/chart=traefik-25.0.2_up25.0.0
                      pod-template-hash=f4564c4f4
Annotations:          prometheus.io/path: /metrics
                      prometheus.io/port: 9100
                      prometheus.io/scrape: true
Status:               Running
IP:                   10.42.0.8
IPs:
  IP:           10.42.0.8
Controlled By:  ReplicaSet/traefik-f4564c4f4
Containers:
  traefik:
    Container ID:  containerd://019a2af5eb21fda2cb230dc362cb778c305a6ca2d6ec915e74faf087ec02b966
    Image:         rancher/mirrored-library-traefik:2.10.5
    Image ID:      docker.io/rancher/mirrored-library-traefik@sha256:ca9c8fbe001070c546a75184e3fd7f08c3e47dfc1e89bff6fe2edd302accfaec
    Ports:         9100/TCP, 9000/TCP, 8000/TCP, 8443/TCP
    Host Ports:    0/TCP, 0/TCP, 0/TCP, 0/TCP
    Args:
      --global.checknewversion
      --global.sendanonymoususage
      --entrypoints.metrics.address=:9100/tcp
      --entrypoints.traefik.address=:9000/tcp
      --entrypoints.web.address=:8000/tcp
      --entrypoints.websecure.address=:8443/tcp
      --api.dashboard=true
      --ping=true
      --metrics.prometheus=true
      --metrics.prometheus.entrypoint=metrics
      --providers.kubernetescrd
      --providers.kubernetesingress
      --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
      --entrypoints.websecure.http.tls=true
    State:          Running
      Started:      Tue, 27 Feb 2024 11:14:55 -0700
    Ready:          True
    Restart Count:  0
    Liveness:       http-get http://:9000/ping delay=2s timeout=2s period=10s #success=1 #failure=3
    Readiness:      http-get http://:9000/ping delay=2s timeout=2s period=10s #success=1 #failure=1
    Environment:
      POD_NAME:       traefik-f4564c4f4-4xlbt (v1:metadata.name)
      POD_NAMESPACE:  kube-system (v1:metadata.namespace)
    Mounts:
      /data from data (rw)
      /tmp from tmp (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-9qfv8 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  data:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  tmp:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  kube-api-access-9qfv8:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 CriticalAddonsOnly op=Exists
                             node-role.kubernetes.io/control-plane:NoSchedule op=Exists
                             node-role.kubernetes.io/master:NoSchedule op=Exists
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  8m33s  default-scheduler  Successfully assigned kube-system/traefik-f4564c4f4-4xlbt to mtl-w-4brym13
  Normal  Pulling    8m33s  kubelet            Pulling image "rancher/mirrored-library-traefik:2.10.5"
  Normal  Pulled     8m26s  kubelet            Successfully pulled image "rancher/mirrored-library-traefik:2.10.5" in 7.527s (7.527s including waiting)
  Normal  Created    8m25s  kubelet            Created container traefik
  Normal  Started    8m25s  kubelet            Started container traefik


Name:             bitcoin-price-app-69f9f994c9-9sgb9
Namespace:        default
Priority:         0
Service Account:  default
Node:             mtl-w-4brym13/172.26.138.62
Start Time:       Tue, 27 Feb 2024 11:17:35 -0700
Labels:           app=bitcoin-price-app
                  pod-template-hash=69f9f994c9
Annotations:      <none>
Status:           Running
IP:               10.42.0.9
IPs:
  IP:           10.42.0.9
Controlled By:  ReplicaSet/bitcoin-price-app-69f9f994c9
Containers:
  bitcoin-price-container:
    Container ID:   containerd://8215c42a6cace2fd16e3f77d8d23d5c1905c424c40761bfb0ab918413b1910ff
    Image:          thomaslifedesign/bitcoin_exporter
    Image ID:       docker.io/thomaslifedesign/bitcoin_exporter@sha256:d5bc08a35da3088280d18a90305a326fb0e37172d7e06cf3e16fe8f08fa85cf8
    Port:           8000/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Tue, 27 Feb 2024 11:17:44 -0700
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-lq85h (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  kube-api-access-lq85h:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  5m44s  default-scheduler  Successfully assigned default/bitcoin-price-app-69f9f994c9-9sgb9 to mtl-w-4brym13
  Normal  Pulling    5m44s  kubelet            Pulling image "thomaslifedesign/bitcoin_exporter"
  Normal  Pulled     5m36s  kubelet            Successfully pulled image "thomaslifedesign/bitcoin_exporter" in 8.704s (8.704s including waiting)
  Normal  Created    5m36s  kubelet            Created container bitcoin-price-container
  Normal  Started    5m36s  kubelet            Started container bitcoin-price-container


Name:             prometheus-deployment-6454fcc569-86skt
Namespace:        default
Priority:         0
Service Account:  default
Node:             mtl-w-4brym13/172.26.138.62
Start Time:       Tue, 27 Feb 2024 11:19:28 -0700
Labels:           app=prometheus
                  pod-template-hash=6454fcc569
Annotations:      <none>
Status:           Running
IP:               10.42.0.10
IPs:
  IP:           10.42.0.10
Controlled By:  ReplicaSet/prometheus-deployment-6454fcc569
Containers:
  prometheus:
    Container ID:   containerd://51f85a14c8a88a0c16ed1ce6fb89a76e44d2a41694de558006493f24b55252aa
    Image:          prom/prometheus:latest
    Image ID:       docker.io/prom/prometheus@sha256:bc1794e85c9e00293351b967efa267ce6af1c824ac875a9d0c7ac84700a8b53e
    Port:           9090/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Tue, 27 Feb 2024 11:19:41 -0700
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /etc/prometheus from prometheus-config-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-km928 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  prometheus-config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      prometheus-config
    Optional:  false
  kube-api-access-km928:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  3m52s  default-scheduler  Successfully assigned default/prometheus-deployment-6454fcc569-86skt to mtl-w-4brym13
  Normal  Pulling    3m52s  kubelet            Pulling image "prom/prometheus:latest"
  Normal  Pulled     3m40s  kubelet            Successfully pulled image "prom/prometheus:latest" in 12.194s (12.194s including waiting)
  Normal  Created    3m39s  kubelet            Created container prometheus
  Normal  Started    3m39s  kubelet            Started container prometheus
