Name:             helm-install-traefik-crd-bwxnh
Namespace:        kube-system
Priority:         0
Service Account:  helm-traefik-crd
Node:             mtl-w-4brym13/172.26.138.62
Start Time:       Tue, 27 Feb 2024 11:14:07 -0700
Labels:           batch.kubernetes.io/controller-uid=9530b900-e7c7-47b6-ac35-509c0444fa2a
                  batch.kubernetes.io/job-name=helm-install-traefik-crd
                  controller-uid=9530b900-e7c7-47b6-ac35-509c0444fa2a
                  helmcharts.helm.cattle.io/chart=traefik-crd
                  job-name=helm-install-traefik-crd
Annotations:      helmcharts.helm.cattle.io/configHash: SHA256=E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855
Status:           Succeeded
SeccompProfile:   RuntimeDefault
IP:               
IPs:              <none>
Controlled By:    Job/helm-install-traefik-crd
Containers:
  helm:
    Container ID:  containerd://e087c190264b151c1628dc5db289d9d187ccc4ae94cf042887071efb38813ffc
    Image:         rancher/klipper-helm:v0.8.2-build20230815
    Image ID:      docker.io/rancher/klipper-helm@sha256:b0b0c4f73f2391697edb52adffe4fc490de1c8590606024515bb906b2813554a
    Port:          <none>
    Host Port:     <none>
    Args:
      install
    State:      Terminated
      Reason:   Completed
      Message:  Installing helm_v3 chart

      Exit Code:    0
      Started:      Tue, 27 Feb 2024 11:14:22 -0700
      Finished:     Tue, 27 Feb 2024 11:14:28 -0700
    Ready:          False
    Restart Count:  0
    Environment:
      NAME:                   traefik-crd
      VERSION:                
      REPO:                   
      HELM_DRIVER:            secret
      CHART_NAMESPACE:        kube-system
      CHART:                  https://%{KUBERNETES_API}%/static/charts/traefik-crd-25.0.2+up25.0.0.tgz
      HELM_VERSION:           
      TARGET_NAMESPACE:       kube-system
      AUTH_PASS_CREDENTIALS:  false
      NO_PROXY:               .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
      FAILURE_POLICY:         reinstall
    Mounts:
      /chart from content (rw)
      /config from values (rw)
      /home/klipper-helm/.cache from klipper-cache (rw)
      /home/klipper-helm/.config from klipper-config (rw)
      /home/klipper-helm/.helm from klipper-helm (rw)
      /tmp from tmp (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-4bvnm (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  klipper-helm:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  klipper-cache:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  klipper-config:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  tmp:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  values:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  chart-values-traefik-crd
    Optional:    false
  content:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      chart-content-traefik-crd
    Optional:  false
  kube-api-access-4bvnm:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              kubernetes.io/os=linux
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>


Name:             helm-install-traefik-pbg2d
Namespace:        kube-system
Priority:         0
Service Account:  helm-traefik
Node:             mtl-w-4brym13/172.26.138.62
Start Time:       Tue, 27 Feb 2024 11:14:07 -0700
Labels:           batch.kubernetes.io/controller-uid=7cda5ef1-bf02-4a96-bf62-9d1b3e708d4e
                  batch.kubernetes.io/job-name=helm-install-traefik
                  controller-uid=7cda5ef1-bf02-4a96-bf62-9d1b3e708d4e
                  helmcharts.helm.cattle.io/chart=traefik
                  job-name=helm-install-traefik
Annotations:      helmcharts.helm.cattle.io/configHash: SHA256=2C8876269AFB411F60BCDA289A1957C0126147D80F1B0AC6BD2C43C10FE296E9
Status:           Succeeded
SeccompProfile:   RuntimeDefault
IP:               
IPs:              <none>
Controlled By:    Job/helm-install-traefik
Containers:
  helm:
    Container ID:  containerd://e032e85c83ee172eb19a78984e5f6e17d98a1b1963442e9b73a2628f36e3c9c9
    Image:         rancher/klipper-helm:v0.8.2-build20230815
    Image ID:      docker.io/rancher/klipper-helm@sha256:b0b0c4f73f2391697edb52adffe4fc490de1c8590606024515bb906b2813554a
    Port:          <none>
    Host Port:     <none>
    Args:
      install
      --set-string
      global.systemDefaultRegistry=
    State:      Terminated
      Reason:   Completed
      Message:  Installing helm_v3 chart

      Exit Code:    0
      Started:      Tue, 27 Feb 2024 11:14:43 -0700
      Finished:     Tue, 27 Feb 2024 11:14:46 -0700
    Ready:          False
    Restart Count:  2
    Environment:
      NAME:                   traefik
      VERSION:                
      REPO:                   
      HELM_DRIVER:            secret
      CHART_NAMESPACE:        kube-system
      CHART:                  https://%{KUBERNETES_API}%/static/charts/traefik-25.0.2+up25.0.0.tgz
      HELM_VERSION:           
      TARGET_NAMESPACE:       kube-system
      AUTH_PASS_CREDENTIALS:  false
      NO_PROXY:               .svc,.cluster.local,10.42.0.0/16,10.43.0.0/16
      FAILURE_POLICY:         reinstall
    Mounts:
      /chart from content (rw)
      /config from values (rw)
      /home/klipper-helm/.cache from klipper-cache (rw)
      /home/klipper-helm/.config from klipper-config (rw)
      /home/klipper-helm/.helm from klipper-helm (rw)
      /tmp from tmp (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-7s2wb (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  klipper-helm:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  klipper-cache:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  klipper-config:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  tmp:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     Memory
    SizeLimit:  <unset>
  values:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  chart-values-traefik
    Optional:    false
  content:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      chart-content-traefik
    Optional:  false
  kube-api-access-7s2wb:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              kubernetes.io/os=linux
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>


Name:                 local-path-provisioner-84db5d44d9-pkp5r
Namespace:            kube-system
Priority:             2000001000
Priority Class Name:  system-node-critical
Service Account:      local-path-provisioner-service-account
Node:                 mtl-w-4brym13/172.26.138.62
Start Time:           Tue, 27 Feb 2024 11:14:07 -0700
Labels:               app=local-path-provisioner
                      pod-template-hash=84db5d44d9
Annotations:          <none>
Status:               Running
IP:                   10.42.0.25
IPs:
  IP:           10.42.0.25
Controlled By:  ReplicaSet/local-path-provisioner-84db5d44d9
Containers:
  local-path-provisioner:
    Container ID:  containerd://1a11e817e4454de97269a2a71598c64451f629fcb324f791db0de718c2965c16
    Image:         rancher/local-path-provisioner:v0.0.24
    Image ID:      docker.io/rancher/local-path-provisioner@sha256:5bb33992a4ec3034c28b5e0b3c4c2ac35d3613b25b79455eb4b1a95adc82cdc0
    Port:          <none>
    Host Port:     <none>
    Command:
      local-path-provisioner
      start
      --config
      /etc/config/config.json
    State:          Running
      Started:      Tue, 27 Feb 2024 17:14:44 -0700
    Last State:     Terminated
      Reason:       Unknown
      Exit Code:    255
      Started:      Tue, 27 Feb 2024 16:54:07 -0700
      Finished:     Tue, 27 Feb 2024 17:14:39 -0700
    Ready:          True
    Restart Count:  4
    Environment:
      POD_NAMESPACE:  kube-system (v1:metadata.namespace)
    Mounts:
      /etc/config/ from config-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-ntxrz (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      local-path-config
    Optional:  false
  kube-api-access-ntxrz:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 CriticalAddonsOnly op=Exists
                             node-role.kubernetes.io/control-plane:NoSchedule op=Exists
                             node-role.kubernetes.io/master:NoSchedule op=Exists
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>


Name:             prometheus-deployment-6454fcc569-86skt
Namespace:        default
Priority:         0
Service Account:  default
Node:             mtl-w-4brym13/172.26.138.62
Start Time:       Tue, 27 Feb 2024 11:19:28 -0700
Labels:           app=prometheus
                  pod-template-hash=6454fcc569
Annotations:      <none>
Status:           Running
IP:               10.42.0.29
IPs:
  IP:           10.42.0.29
Controlled By:  ReplicaSet/prometheus-deployment-6454fcc569
Containers:
  prometheus:
    Container ID:   containerd://c071a6e2b55430d4185d9b493c3f66948a91531bb3b08ead5f94f03e268a6cfb
    Image:          prom/prometheus:latest
    Image ID:       docker.io/prom/prometheus@sha256:bc1794e85c9e00293351b967efa267ce6af1c824ac875a9d0c7ac84700a8b53e
    Port:           9090/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Tue, 27 Feb 2024 17:14:45 -0700
    Last State:     Terminated
      Reason:       Unknown
      Exit Code:    255
      Started:      Tue, 27 Feb 2024 16:53:25 -0700
      Finished:     Tue, 27 Feb 2024 17:14:39 -0700
    Ready:          True
    Restart Count:  3
    Environment:    <none>
    Mounts:
      /etc/prometheus from prometheus-config-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-km928 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  prometheus-config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      prometheus-config
    Optional:  false
  kube-api-access-km928:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>


Name:             bitcoin-price-app-69f9f994c9-9sgb9
Namespace:        default
Priority:         0
Service Account:  default
Node:             mtl-w-4brym13/172.26.138.62
Start Time:       Tue, 27 Feb 2024 11:17:35 -0700
Labels:           app=bitcoin-price-app
                  pod-template-hash=69f9f994c9
Annotations:      <none>
Status:           Running
IP:               10.42.0.27
IPs:
  IP:           10.42.0.27
Controlled By:  ReplicaSet/bitcoin-price-app-69f9f994c9
Containers:
  bitcoin-price-container:
    Container ID:   containerd://c9a9090844e9e5eaeaeee0f4e63a965263798452431f7b8932a3e1aebb4f67e2
    Image:          thomaslifedesign/bitcoin_exporter
    Image ID:       docker.io/thomaslifedesign/bitcoin_exporter@sha256:d5bc08a35da3088280d18a90305a326fb0e37172d7e06cf3e16fe8f08fa85cf8
    Port:           8000/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Tue, 27 Feb 2024 17:14:45 -0700
    Last State:     Terminated
      Reason:       Unknown
      Exit Code:    255
      Started:      Tue, 27 Feb 2024 16:53:25 -0700
      Finished:     Tue, 27 Feb 2024 17:14:39 -0700
    Ready:          True
    Restart Count:  3
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-lq85h (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  kube-api-access-lq85h:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>


Name:                 coredns-6799fbcd5-ptsvw
Namespace:            kube-system
Priority:             2000000000
Priority Class Name:  system-cluster-critical
Service Account:      coredns
Node:                 mtl-w-4brym13/172.26.138.62
Start Time:           Tue, 27 Feb 2024 11:14:07 -0700
Labels:               k8s-app=kube-dns
                      pod-template-hash=6799fbcd5
Annotations:          <none>
Status:               Running
IP:                   10.42.0.30
IPs:
  IP:           10.42.0.30
Controlled By:  ReplicaSet/coredns-6799fbcd5
Containers:
  coredns:
    Container ID:  containerd://e92255ce2b822e091dc16cb4a1240699e6b7e3f8ef716c90647d17918beac923
    Image:         rancher/mirrored-coredns-coredns:1.10.1
    Image ID:      docker.io/rancher/mirrored-coredns-coredns@sha256:a11fafae1f8037cbbd66c5afa40ba2423936b72b4fd50a7034a7e8b955163594
    Ports:         53/UDP, 53/TCP, 9153/TCP
    Host Ports:    0/UDP, 0/TCP, 0/TCP
    Args:
      -conf
      /etc/coredns/Corefile
    State:          Running
      Started:      Tue, 27 Feb 2024 17:14:44 -0700
    Last State:     Terminated
      Reason:       Unknown
      Exit Code:    255
      Started:      Tue, 27 Feb 2024 16:53:24 -0700
      Finished:     Tue, 27 Feb 2024 17:14:39 -0700
    Ready:          True
    Restart Count:  3
    Limits:
      memory:  170Mi
    Requests:
      cpu:        100m
      memory:     70Mi
    Liveness:     http-get http://:8080/health delay=60s timeout=1s period=10s #success=1 #failure=3
    Readiness:    http-get http://:8181/ready delay=0s timeout=1s period=2s #success=1 #failure=3
    Environment:  <none>
    Mounts:
      /etc/coredns from config-volume (ro)
      /etc/coredns/custom from custom-config-volume (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-snh5x (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      coredns
    Optional:  false
  custom-config-volume:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      coredns-custom
    Optional:  true
  kube-api-access-snh5x:
    Type:                     Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:   3607
    ConfigMapName:            kube-root-ca.crt
    ConfigMapOptional:        <nil>
    DownwardAPI:              true
QoS Class:                    Burstable
Node-Selectors:               kubernetes.io/os=linux
Tolerations:                  CriticalAddonsOnly op=Exists
                              node-role.kubernetes.io/control-plane:NoSchedule op=Exists
                              node-role.kubernetes.io/master:NoSchedule op=Exists
                              node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                              node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Topology Spread Constraints:  kubernetes.io/hostname:DoNotSchedule when max skew 1 is exceeded for selector k8s-app=kube-dns
Events:                       <none>


Name:             svclb-traefik-c42f2c04-chxbj
Namespace:        kube-system
Priority:         0
Service Account:  svclb
Node:             mtl-w-4brym13/172.26.138.62
Start Time:       Tue, 27 Feb 2024 11:14:46 -0700
Labels:           app=svclb-traefik-c42f2c04
                  controller-revision-hash=749c84f7df
                  pod-template-generation=1
                  svccontroller.k3s.cattle.io/svcname=traefik
                  svccontroller.k3s.cattle.io/svcnamespace=kube-system
Annotations:      <none>
Status:           Running
IP:               10.42.0.31
IPs:
  IP:           10.42.0.31
Controlled By:  DaemonSet/svclb-traefik-c42f2c04
Containers:
  lb-tcp-80:
    Container ID:   containerd://06c7dc03ce16408984e669561eb54dbc9cb9dcf338d82037316c05751989bcbe
    Image:          rancher/klipper-lb:v0.4.5
    Image ID:       docker.io/rancher/klipper-lb@sha256:fa2257de248f46c303d0f39a8ebe8644ba5ac63d332c7d02bf6ee26a981243bc
    Port:           80/TCP
    Host Port:      80/TCP
    State:          Running
      Started:      Tue, 27 Feb 2024 17:14:45 -0700
    Last State:     Terminated
      Reason:       Unknown
      Exit Code:    255
      Started:      Tue, 27 Feb 2024 16:53:24 -0700
      Finished:     Tue, 27 Feb 2024 17:14:39 -0700
    Ready:          True
    Restart Count:  3
    Environment:
      SRC_PORT:    80
      SRC_RANGES:  0.0.0.0/0
      DEST_PROTO:  TCP
      DEST_PORT:   80
      DEST_IPS:    10.43.132.65
    Mounts:        <none>
  lb-tcp-443:
    Container ID:   containerd://4c3b01745bbe3ffbb9b3705ad248c8854c0ef507658b7cafe966098986bd9bce
    Image:          rancher/klipper-lb:v0.4.5
    Image ID:       docker.io/rancher/klipper-lb@sha256:fa2257de248f46c303d0f39a8ebe8644ba5ac63d332c7d02bf6ee26a981243bc
    Port:           443/TCP
    Host Port:      443/TCP
    State:          Running
      Started:      Tue, 27 Feb 2024 17:14:45 -0700
    Last State:     Terminated
      Reason:       Unknown
      Exit Code:    255
      Started:      Tue, 27 Feb 2024 16:53:25 -0700
      Finished:     Tue, 27 Feb 2024 17:14:39 -0700
    Ready:          True
    Restart Count:  3
    Environment:
      SRC_PORT:    443
      SRC_RANGES:  0.0.0.0/0
      DEST_PROTO:  TCP
      DEST_PORT:   443
      DEST_IPS:    10.43.132.65
    Mounts:        <none>
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:            <none>
QoS Class:          BestEffort
Node-Selectors:     <none>
Tolerations:        CriticalAddonsOnly op=Exists
                    node-role.kubernetes.io/control-plane:NoSchedule op=Exists
                    node-role.kubernetes.io/master:NoSchedule op=Exists
                    node.kubernetes.io/disk-pressure:NoSchedule op=Exists
                    node.kubernetes.io/memory-pressure:NoSchedule op=Exists
                    node.kubernetes.io/not-ready:NoExecute op=Exists
                    node.kubernetes.io/pid-pressure:NoSchedule op=Exists
                    node.kubernetes.io/unreachable:NoExecute op=Exists
                    node.kubernetes.io/unschedulable:NoSchedule op=Exists
Events:             <none>


Name:                 traefik-f4564c4f4-4xlbt
Namespace:            kube-system
Priority:             2000000000
Priority Class Name:  system-cluster-critical
Service Account:      traefik
Node:                 mtl-w-4brym13/172.26.138.62
Start Time:           Tue, 27 Feb 2024 11:14:46 -0700
Labels:               app.kubernetes.io/instance=traefik-kube-system
                      app.kubernetes.io/managed-by=Helm
                      app.kubernetes.io/name=traefik
                      helm.sh/chart=traefik-25.0.2_up25.0.0
                      pod-template-hash=f4564c4f4
Annotations:          prometheus.io/path: /metrics
                      prometheus.io/port: 9100
                      prometheus.io/scrape: true
Status:               Running
IP:                   10.42.0.28
IPs:
  IP:           10.42.0.28
Controlled By:  ReplicaSet/traefik-f4564c4f4
Containers:
  traefik:
    Container ID:  containerd://b451a25f1facff5906818fb86af31e7312da778e42dfcb74ef23c19286517191
    Image:         rancher/mirrored-library-traefik:2.10.5
    Image ID:      docker.io/rancher/mirrored-library-traefik@sha256:ca9c8fbe001070c546a75184e3fd7f08c3e47dfc1e89bff6fe2edd302accfaec
    Ports:         9100/TCP, 9000/TCP, 8000/TCP, 8443/TCP
    Host Ports:    0/TCP, 0/TCP, 0/TCP, 0/TCP
    Args:
      --global.checknewversion
      --global.sendanonymoususage
      --entrypoints.metrics.address=:9100/tcp
      --entrypoints.traefik.address=:9000/tcp
      --entrypoints.web.address=:8000/tcp
      --entrypoints.websecure.address=:8443/tcp
      --api.dashboard=true
      --ping=true
      --metrics.prometheus=true
      --metrics.prometheus.entrypoint=metrics
      --providers.kubernetescrd
      --providers.kubernetesingress
      --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
      --entrypoints.websecure.http.tls=true
    State:          Running
      Started:      Tue, 27 Feb 2024 17:14:44 -0700
    Last State:     Terminated
      Reason:       Unknown
      Exit Code:    255
      Started:      Tue, 27 Feb 2024 16:53:24 -0700
      Finished:     Tue, 27 Feb 2024 17:14:39 -0700
    Ready:          True
    Restart Count:  3
    Liveness:       http-get http://:9000/ping delay=2s timeout=2s period=10s #success=1 #failure=3
    Readiness:      http-get http://:9000/ping delay=2s timeout=2s period=10s #success=1 #failure=1
    Environment:
      POD_NAME:       traefik-f4564c4f4-4xlbt (v1:metadata.name)
      POD_NAMESPACE:  kube-system (v1:metadata.namespace)
    Mounts:
      /data from data (rw)
      /tmp from tmp (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-9qfv8 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  data:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  tmp:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  kube-api-access-9qfv8:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 CriticalAddonsOnly op=Exists
                             node-role.kubernetes.io/control-plane:NoSchedule op=Exists
                             node-role.kubernetes.io/master:NoSchedule op=Exists
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>


Name:                 metrics-server-67c658944b-cwbnw
Namespace:            kube-system
Priority:             2000001000
Priority Class Name:  system-node-critical
Service Account:      metrics-server
Node:                 mtl-w-4brym13/172.26.138.62
Start Time:           Tue, 27 Feb 2024 11:14:07 -0700
Labels:               k8s-app=metrics-server
                      pod-template-hash=67c658944b
Annotations:          <none>
Status:               Running
IP:                   10.42.0.26
IPs:
  IP:           10.42.0.26
Controlled By:  ReplicaSet/metrics-server-67c658944b
Containers:
  metrics-server:
    Container ID:  containerd://359065b17e757751be8324764c5f3aab95fd5feb345b92c4397150d7e109fd5e
    Image:         rancher/mirrored-metrics-server:v0.6.3
    Image ID:      docker.io/rancher/mirrored-metrics-server@sha256:c2dfd72bafd6406ed306d9fbd07f55c496b004293d13d3de88a4567eacc36558
    Port:          10250/TCP
    Host Port:     0/TCP
    Args:
      --cert-dir=/tmp
      --secure-port=10250
      --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      --kubelet-use-node-status-port
      --metric-resolution=15s
      --tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305
    State:          Running
      Started:      Tue, 27 Feb 2024 17:14:44 -0700
    Last State:     Terminated
      Reason:       Unknown
      Exit Code:    255
      Started:      Tue, 27 Feb 2024 16:54:20 -0700
      Finished:     Tue, 27 Feb 2024 17:14:39 -0700
    Ready:          True
    Restart Count:  4
    Requests:
      cpu:        100m
      memory:     70Mi
    Liveness:     http-get https://:https/livez delay=60s timeout=1s period=10s #success=1 #failure=3
    Readiness:    http-get https://:https/readyz delay=0s timeout=1s period=2s #success=1 #failure=3
    Environment:  <none>
    Mounts:
      /tmp from tmp-dir (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-m9ljg (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  tmp-dir:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:     
    SizeLimit:  <unset>
  kube-api-access-m9ljg:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Burstable
Node-Selectors:              <none>
Tolerations:                 CriticalAddonsOnly op=Exists
                             node-role.kubernetes.io/control-plane:NoSchedule op=Exists
                             node-role.kubernetes.io/master:NoSchedule op=Exists
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:                      <none>
